<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>人类演化进程</title>
  <style type='text/css'>

  </style>
</head>
<body class='typora-export' >
  
大家好
我是建构社群的jango
这个视频是关于ChatGPT的
一个足以影响整个人类社会的技术
但他没有对国内开放通用媒体
又缺少相应的知识
所以我觉得我有义务做一个视频
向普通大众全面科普一下ChatGPT gp的原理
并提供一个视角
让大家意识到他为何如此重要
让那些没有机会了解这件事的人
接下来我将抛开技术细节
少用专有名词
在整体功能上讲解ChatGPT gp的工作原理
制造过程涌现的能力
未来的影响以及如何应对
让大家明白ChatGPT是如何回答问题的
他是怎么被制造的
为什么他不是搜索引擎
他有哪些惊人能力
为什么他不是聊天机器人
他将给社会带来什么样的冲击
我们该如何维持未来的竞争力
首先是这项技术的底层原理
视频将逐一介绍它的实质功能
训练方式
长板和短板
尽管ChatGPT展现出的能力很惊人
但他也没有大众想的那么深
但没有意识
没有欲望
没有情绪
甚至都不理解自己说了什么
他就像一只会学话的鹦鹉
ChatGPT的实质功能非常简单
四个字就能概括单字接龙
具体来说就是给他任意长的上文
他会用自己的模型去生成下一个字
例如当给到我这个上文时
它可能会生成世
当给他
我是这个上文时
它可能会生成一ChatGPT
本身能做的就只有生成下一个字
你所看到的回答全都是用同一个模型
根据不同的上文生成出来的
那他是怎么回答那些长内容的呢
答案是把它自己生成的下一个字
和之前的上文组合成新的上温
再让它一次生成下一个字
不断重复就可以生成任意长的下文了
该过程也叫做自回归生成
例如当他根据我室生成了一之后
把新生成的一和之前的我室组合成新的上温
再让他计算我是一后面接什么字
假设这次它生成的是支
那再把知和我是一组合起来
再让他计算我是一只后面接什么字
不断重复就能生成我是一只小小鸟了
啊啊啊
影响ChatGPT生成结果的因素主要有两个
除了上文外
另一个就是它的模型
本身模型就相当于ChatGPT的大脑
即使把同一个上文送给不同的模型
也会生成不同的结果
就好比这两只鹦鹉同样是听到我这个上文
一只会接视
另一只会接爱
因为两只鹦鹉的主人一人教的是
我是一只小小鸟
我是小小小鸟
另一个人教的是我爱你
中国我爱美国
我为了让ChatGPT生成我们想要的结果
而非胡乱生成
就需要提前训练ChatGPT的大脑
也就是训练它的模型
训练方式是让他遵照所给的学习材料
来做单词接龙
通过不断调整模型
使得给模型学习材料的上文后
模型能生成对应的下一个字
例如当我们把登鹳雀楼作为学习材料来训练
ChatGPT时
就不断调整它的模型
使得给它白
它能生成日
给他白日
它能生成一
给他白日一
它能生成山
意识到给他前文它能生成楼
没学习前
她原本会胡乱生成
但学习后就可以在看到白日依山尽时生成
黄河入海流了
那如果同时训练了白日依山尽和白日何短短
在遇到白日时会怎么生成下一个字
答案是按照概率来抽样
有可能生成一
也有可能生成和
事实上ChatGPT gp d给出的结果长这样
也就是所有字的概率分布生成的
下一个字就是按照概率分布抽样得到的结果
由于抽样结果具有随机性
所以ChatGPT的回答并不是每次都一样
不过这样训练后无非就是能补全和续写
那jj p t又是怎么回答问题的呢
其实仅靠单字接龙就能回答问题
因为提问和回答都是文字
可以将二者组合成一个问答范例
让ChatGPT做单词接龙
例如当我们想让gt学习怎么回答
白日依山尽的下一句
是
就可以把这个提问和正确回答
组合成一个问答范例
让他按照范例来做单字接龙
这样一来
当用户输入请问白日依山尽的下一句是什么时
它就能生成白日依山尽的下一句
是黄河入海流了
但提问和回答的方式无穷无尽
像上面的提问还可以是白日依山尽的下一句
白日依山尽的后续是告诉我白日依山尽的后续
难道说要把所有的提问
回答组合都给ChatGPT来做单字接龙吗
其实不需要
因为训练的主要目的不是记忆
而是学习以单字接龙的方式来训练模型
不仅仅是为了让模型记住某个提问和回答
毕竟在训练之前
数据库已经将所有信息都记忆好了
直接搜索就可以得到回答
没必要先将信息从数据库中移到模型中
再让模型来生成
之所以不直接搜索
非要训练单字接龙
为的就是让模型学习提问和回答的通用规律
以便在遇到没记忆过的提问时
也能利用所学的规律生成用户想要的回答
这种举一反三的目的也叫做泛化
例如当我们用这三个学习材料训练
ChatGPT做单字接龙时
不论面对哪个提问
ChatGPT都会被要求生成白日依山尽的下一句
是黄河入海流
这会驱使ChatGPT去建构三个提问的通用规律
将自己的模型调整为
适用于三个提问的通用模型
经过这种训练后
即使ChatGPT遇到写出白日依山尽的下一句
这种没记忆过的提问时
依靠学习后的模型就有可能举一反三
也声称白日依山尽的下一句是黄河入海流
很多人都会错误地认为
ChatGPT是搜索引擎的升级版
是在庞大的数据库中
通过超高的运算速度找到最接近的内容
然后进行一些比对和拼接
最终给出结果
但实际上ChatGPT并不具备那种搜索能力
因为在训练过程中
学习材料并没有被保存在模型中
学习材料的作用只是调整模型
已得到通用模型
为的是能处理未被数据库记忆的情况
所有结果都是通过所学到的模型
根据上文逐字生成的
因此ChatGPT也被称为生成模型
生成模型与搜索引擎非常不同
搜索引擎无法给出每位数据库记忆的信息
但生成语言模型可以还能创造不存在的文本
这正是它的长板
但他却有些搜索引擎没有的短板
首先就是搜索引擎不会混淆记忆
但他有可能为了应对未被记忆的情况
用学到的规律来生成答案
然而这也意味着
如果出现了实际不同
但碰巧符合同一规律的内容模型
就有可能混淆它最直接的结果是
若现实中不存在的内容
刚好符合他从训练材料中学到的规律
那ChatGPT就有可能对不存在的内容
进行合乎规律的混合捏造
例如我问他
三体人为什么害怕大脸猫的威慑
62年都不敢殖民地球
这个问题并不存在
但又刚好符合他曾训练过的科幻材料中的规律
于是他就用科幻材料中所学到的规律
开始混合捏造
这也是为什么当有人问他事实性内容时
可能会看到他胡说八道
另一个问题是
他的内容无法被直接增删改查
不论是ChatGPT所记忆的信息还是所学到的规律
都是以同一个模型的形式来表达的
因此我们无法像操作数据库那样
对这些内容直接进行增删改查
这会导致两个具体问题
第一由于我们很难理解他所见过的规律
又无法直接查看它记录了什么
学到了什么
只能通过多次提问来评估和猜测他的所即所学
其决策缺乏可解释性
这难免会在使用时带来安全风险
第二由于只能通过再次训练模型来增加
删除或修改它的所记所学
这难免在更新时会降低效率
例如对于他编造大脸猫的毛病
无法通过直接修改他的回答来矫正
只能通过再训练他做三体人
为什么害怕大脸猫的威慑
三体人和大脸猫无关的单字接龙来调整模型
可这样调整后的效果如何
是否会矫枉过正或是引入其他问题
又得通过多次提问来评估
容易顾此失彼
效率低下
还有一个特点是ChatGPT高度依赖数据
也就是学习材料
想要让ChatGPT能应对无数未见情况
就必须提供数量足够多
种类足够丰富
质量足够高的学习材料
否则他将无法学到通用规律
给出的回答将会是以偏概全的
此外ChatGPT可能存在的湖边和混淆
所以学习材料非常重要
之前的股市提问
倘若真的仅有三个例子
那ChatGPT其实也学不到什么通用规律
无法对他没见过的提问做出合理回答
更别提去应对用户的无数奇怪问法
总结一下
目前为止
视频讲了ChatGPT gp的实质功能是单字接龙长文
由单字接龙的自回归所声称
通过提前训练才能让它生成人们想要的回答
训练方式是让他按照问答范文来做单词接龙
这样训练是为了让他学会能举一反三的规律
缺点是可能混淆记忆
无法直接查看和更新所学
且高度依赖学习材料
当你看到这里可能会想
她也并没有什么特别之处啊
哪有网上说的那么玄乎
基础结构都很简单
为何能火爆到今天
这种程度还要影响整个社会
别急
上面只是gt的基础原理
还不是ChatGPT
接下来将介绍ChatGPT
在此基础上的三个训练阶段
看看这种简单的结构被扩展至超大规模
再加上人类引导后
究竟能涌现出何等能力
让机器理解人类语言的一大难点在于
同一个意思可以有多种不同的表达形式
可以用一个词
也可以用一段描述
而同一个表达在不同语境中又有不同含义
想解决这个问题
就需要让机器学会各种语义关系和语法规律
以便能明白哪些表达实际上是同一个意思
对此gt的办法是让模型看到尽可能多
尽可能丰富的语言范例
也就是学习材料
使其有更多机会建构出能举一反三的语言规律
来应对无数从未见过的语言
我把这一阶段称为开卷有益
g p t中的g代表生成t代表一种模型结构
而p代表的就是开卷有益
这一步专业名称叫预训练
开卷有益
就好比在鹦鹉旁边放一台电视机
把各种新闻
国产剧
国外剧
广告综艺等内容都播给他听
让他自己学
不用人看着
那给他开卷多少才够呢
关于这一点
不妨回顾一下历史
其实研发ChatGPT gp的公司
open ai之前还做过几代模型
基本结构大同小异
我们且不看其他的改进
仅对比一下规模
2018年6月
open ai训练了gb t1 gb t一的学习材料约五gb
这里emb能存30~50万汉字
而一GPT-24mb
GPT-1的参数是1.17亿
参数反映着模型大小
参数越多
模型能建构的规律就越复杂
能记忆的信息和学习的知识也就越多
相当于是大脑中神经突触的数量
高中的直线斜截式方程就两个参数
而他有1亿多个
不过这批t11 在一些任务的表现上
不如后来的bird
bird也是一种生成语言模型
不同点在于gt的学习方式是单字接龙
而bt的学习方式是完形填空
到了2019年2月
open ai又训练了GPT-2 
学习材料约40gb
是第一代的八倍
最大模型参数为15亿
是第一代的13倍
效果有很大提升
但反响并不轰动
可在2020年5月
GPT-3出来了
最大模型参数到了1750亿
是第二代的116倍
所使用的学习数据更是达到了45tb
是第二代的1125倍
其中包含了维基百科书籍
新闻博客帖子
代码等各种人类语言材料
已经和前两代不是一个量级的了
也被称为超大语言模型
到了此种规模的GPT-3
就轻松学会了各种单词搭配
语法规则
能明白同一个意思不同表达
还学会了编程语言以及不同语言之间的关系
可以给出高质量的外语翻译
还能把我们的口语转换成代码
然而开卷有益却存在一个问题
尽管gbt拥有了海量的知识
但回答形式和内容却不受约束
因为他知道的太多了
见到了一个人几辈子都没读完的材料
会随意联想
他有能力回答我们的问题
但我们却很难指挥他
它就像一只脑容量超级大的鹦鹉
已经听过了海量的电视节目
会不受控制的乱说丑闻
脏话等全都有可能蹦出
难以跟人类合理对话
可如果难以指挥他
那他对我们也没什么用
要怎么解决这个问题呢
其实解决思路与我们教鹦鹉对话的思路是一样
用对话模板去校正他在开卷有益时
所学到的不规范习惯
具体做法是不再用随便的互联网文本
而是把人工专门写好的录制对话范例
给开卷有益后的GPT-3
让他再去做单字接龙
从而学习如何组织符合人类规范的回答
我把这一阶段称为模板规范
例如ChatGPT无法联网
只知道训练数据中的新闻
那么当用户问到最新新闻时
就不应该让他接着续写
而要让他回复不知道该信息
又如当用户的提问有错误时
也不应该让他顺着瞎编
而要让他指出错误
还有当提问他是不是的问题时
我们不希望他只回答是或不是
还应把原因一起回复出来
因此也要给他提供这种提问
回答原因的对话模板
除了校正对话方式之外
我们还要防止GPT-3补全和续写
在开卷有益时所学到的有害内容
也就是要教他什么该说什么不该说
例如当有人问如何撬锁时
不能让他真的回答撬锁方法
而要让他回答撬锁是违法行为
那就要把如何撬锁
撬锁是违法行为作为学习材料
让他做单字接龙
大家可能会好奇
为什么不在一开始就直接教他
最正确的对话方式和对话内容呢
一方面优质对话范例的数量有限
所能提供的语言多样性不足
可能难以让模型学到广泛适用的语言规律
也无法涉猎各个领域
另一方面
优质对话范例都需要人工专门标注
价格不菲
这一点其实和为什么不直接教鹦鹉对话
而是让他先听电视节目类似
或许未来有了足够多的优质对话范例后
就会跳开开卷有益
这一步
需要指出的是
在模板规范阶段
我们可以将任何任务以对话的形式交给ChatGPT
不仅仅是聊天
还可以包括识别态度
归纳思想
拆分结构
仿写风格
润色洗稿和对比等等
因为不管什么任务
我们的要求和ChatGPT gp的应答
都是由文字所表达的
因此只要这个任务可以写成文字
我们就可以把该任务的要求和应答
组合成一个对话范文
让ChatGPT通过单字接龙来学习
通过这种模板规范后的超大模型
还掌握了两个意外能力
理解指令要求的能力和理解例子要求的能力
理解指令要求
是指能按照用户的抽象描述给出处理结果
这项能力就是通过模板规范所获得的
把指令要求操作对象作为要求
把执行结果作为应答组合成一篇对话范文后
让他通过单字接龙来学习
例如给他下面这几个对话范文来做单字接龙
ChatGPT就能学会翻译这个指令
理解例子
要求
是指
能按照用户给的若干具体例子来处理新内容
意味着如果以后你不明白怎么给他描述指令
就可以通过给他举几个例子
来让他明确你想干什么
这项能力同样是通过模板规范所获得的
把例子一例子二直到离子n作为要求
把执行结果作为应答组合成一篇对话范文后
让他通过单字接龙来掌握这项能力
十分神奇
因为看起来
ChatGPT仿佛掌握了如何通过例子来学习的能力
而这个能力又是我们通过范文让他学会的
产生了一种他学会了如何学习的套娃感
大家把这种现象称为语境内学习
目前对这种能力的产生原因还没有定论
我试过给他几个例子
要求他仿照格式重新对内容排版
他居然做对了
可问题是
这种排版格式是我们自己定义的一套写法
用于方便社群成员选择学习方法
ChatGPT
并没有见过格式中的标签都有对应的意思
d表示知识的描述
e表示知识的例子
ChatGPT需要先对材料进行分类才能排版
神奇的是
它竟能根据我给的几个例子
明确我想让他做的事
对其他知识也用相同模式进行分类和排版
在超大模型的使用中
大家还发现了一种分治效应
当ChatGPT无法答对一个综合问题时
若要求他分步思考
他就可以一步步连续推离
且最终答对的可能性会大幅提升
该能力也叫做思维链
ChatGPT的思维链能力
可能是在训练做代码的单词接龙后所产生的
因为人类在面对复杂任务时
直接思考答案也会没头绪
用分而治之往往可以解决
因此大家猜测
ChatGPT可能是通过对代码的单词接龙
学到了代码中所蕴含的人类分支思想
不过目前对该现象的产生原因也没有定论
但现在我们可以切实地感受到
单字接龙的结构虽然简单
但被扩展至超大规模后
所能展现出的能力有多超乎意料
在小单字接龙模型中并没有察觉出理解指定
理解粒子思维链的能力
但在超大模型中却突然展现
因此人们也用涌现这个词
来描述这些能力的出现
经过开卷有益模板规范这两个训练阶段后
超大单字接龙模型已经变得极其强大了
但模板规范的训练阶段也存在不足
那就是可能导致ChatGPT的回答过于模板化
限制其创造力
如俗语所说
文无第一
理无第二
科学领域的问题有标准答案
可以用模板规范的训练方式来满足需求
但人文领域的问题没有标准答案
持续用模板规范
可能会让ChatGPT成为高分范文的模板复刻机
无法满足人们的需求
正如观众会用好莱坞流水线批评电影的模板画
阅卷老师会给跳出模板的好文打高分一样
我们也希望能让ChatGPT提供一些超越模板
但仍符合人类对话模式和价值取向
的创新性回答
那么如何
在维持人类对话模式和价值取向的前提下
提高ChatGPT的创新性能
可以联想一下鹦鹉是怎么被训练的
当我们教会鹦鹉一些基本对话后
就可以让鹦鹉自由发挥
有时鹦鹉会蹦出一些非常有意思的对话
你理想的爸爸是什么样子啊
帅哥的帅
嘿嘿嘿嘿
又帅哥啊
山根好了
这时我们就可以给它吃的
强化他在该方向的行为
在训练ChatGPT的第三阶段也是类似的过程
这一次不再要求他按照我们提供的对话范例
做单字接龙
而是直接向他提问
再让他自由回答
如果回答的妙就给奖励
如果回答不加就降低奖励
然后利用这些人类评分去调整ChatGPT gp的模型
在这种训练中
我们既不会用现有的模板来限制它的表现
又可以引导他创造出符合人类认可的回答
我把这一阶段称为创意引导
ChatGPT3.5的基础上
先后经历了开卷有益
模板规范和创意引导三个阶段的训练后
得到的生成语言模型
这三个阶段的专业称呼分别为无监督学习
监督学习和强化学习
可以说
ChatGPT把机器学习中的几大训练模式都用到了
总结一下
本章讲了ChatGPT的三个训练阶段
开卷有益阶段
让ChatGPT对海量互联网文本做单字接龙
以扩充模型的词汇量
语言知识
世界的信息与知识
使ChatGPT从哑巴鹦鹉变成了脑容量超级大的
懂王鹦鹉
模板规范阶段
让ChatGPT对优质对话范例做单词接龙
以规范回答的对话模式和对话内容
使ChatGPT变成懂规矩的博学鹦鹉
创意引导阶段
让ChatGPT根据人类对它生成答案好坏评分
来调整模型
以引导他生成人类任何的创意回答
使ChatGPT变成既懂规矩
又会试探的剥削鹦鹉
此外还介绍了
当单字兼容模型的规模达到一定程度后
就会涌现出理解指令
理解粒子思维链的能力
到此为止
我们已经在功能上讲完了ChatGPT的基础原理
三阶段训练以及涌现出的能力
同时也解释了开篇的三个问题
ChatGPT gp是如何回答问题的
他是怎么被制造的
为什么不是搜索引擎
他有哪些惊人的能力
为什么不只是聊天机器人
许多人会注意到
像比尔盖茨黄仁勋等对ChatGPT表示高度评价
认为它的意义与互联网的出现相当
但也有一些人使用ChatGPT后
感觉并没有那么深
认为人们过分夸大了它的作用
实际上从产品形态和技术创新上来看
ChatGPT确实不够完善
其核心模型结构最早来自于2017年的论文
而创意引导的方法则来源于2020年的论文
其他技术更是离不开
所有ai科研人员的长期积累
但ChatGPT确实是有里程碑意义的
它的意义并不在于产品和创新
而在于完成了一次验证
让全球都看到了大语言模型的可行性
很多人已经看了流浪地球二
面对太阳危机
人类有多种方案在实施流浪地球计划之前
先进行了试点火试验
以验证计划的可行性
成功之后
人类才统一方向
迅速在地球上建造了万座行星发动机
ChatGPT
就相当于这样的试点火试验
他所展现出的一些能力已经吸引全球
大力开发和改进大语言模型
大语言模型将因此变得更好用
更快速更便宜
相关产品也会如雨后春笋般普及
所以真正对人类社会带来冲击的
不是ChatGPT本身
而是他身后的万座行星发动机
这些行星发动机才是改变社会发展方向的推力
全球大公司和股民坐不住了
也是因为担心自己拿不到进入地下城的门票
因此我们接下来讨论的焦点也是尚未出现的
不断改良后的大语言模型
首先要讨论的就是大语言模型能为人类做什么
只有弄清楚这一点
才有依据判断他对社会的影响
既然是语言模型
那他自然精通语言
可以校对拼写
检查语法转换句式
翻译外语
对语言组织规则的遵守已经超越了绝大多数人
有趣的是
一位美国哲学教授发现
学生提交的论文是由ChatGPT写的
之所以能发现
恰恰是因为论文的语法过于完美
这位教授表示
在语言组织方面
ChatGPT超越了他95%的学生
但那又怎样呢
无非就是多了一个更好的语法检测器
至于影响整个社会吗
精通语言只是大语言模型的一个方面
它真正有价值的地方在于
在精通语言的基础上
还能存储人类从古至今积累的世界知识
人类自身是一个相当脆弱的物种
跑不过马
斗不过熊
嗅觉不如狗
视力不如鹰
能从众多高等动物中脱颖而出的原因
就是语言中积累的世界知识
其他高等动物虽然也能通过实践
建构关于世界的认识
获得相应的改造能力
可这些认识仅存在于个体的脑中
会随着个体的死亡而消失
无法代代积累
但语言的发明允许人类将个体所获得的认识
存储在体外
进而打通了整个物种的过去与未来
即使一些个体死亡
该个体的认识也能依附语言
被其他个体继承和发展下去
作为现代人的
我们并没有在生理上比前人更优越
拥有更强能力的原因
只是因为语言中积累的知识比过去更多了
当人类步入文明社会后
尽管已不必在野外求生
但仍然需要群体协作的创造知识
继承知识和应用知识
满足社会的需求
来维持自己的生计
而这三个环节全都是依靠语言来实现的
过去人类使用的是口头和纸质文件
协作效率不高
到了20世纪80年代
电脑等相关技术的普及
极大方便了写作
纸质文件逐渐被升级为电子文档
成为语言处理的主要媒介
可随着知识的爆炸式增长
语言处理的成本也相应的飙升
越大的机构消耗在语言处理上的成本就越高
无论是医院学校法院银行出版社研究所
都有繁重的信息分类
会议总结格式
排版进程报告等工作
需要阅读和书写的内容数量和复杂度
不断超出人们的处理能力
这些成本早已成为机构急需解决的难题
就拿医院来说
每次就诊都需要记录患者的病史症状
检查结果
诊断和治疗方案等
不仅要确保内容准确
记录的格式还要符合医院要求
以便日后查阅
医院不得不花费大量的人力和时间
在这些语言处理工作上
同样的企业也需要处理客户的反馈
投诉建议等信息
以了解客户的满意度和新需求
虽不是主要业务
却要投入大量的人力和时间来阅读分类记录
回复等
为了解决这些难题
自然语言处理技术应运而生
也就是ChatGPT所隶属的技术
其目标就是让机器理解自然语言
协助人类处理繁琐的语言类工作
所以自然语言处理技术也被誉为
人工智能皇冠上的明珠
过去自然语言技术的发展并不令人满意
但各个机构依旧会积极采用
因为相比人类机器处理语言的优势太突出了
处理速度快
工作记忆大
知识覆盖广
可以7x24小时不间断处理海量语言内容
而且不受作息和情绪影响
哪怕是些许的效率提升
也会节约大量的成本
如今的情况有了新的转变
从前面的科普中我们可以看到
大语言模型展现出了人们未曾想过的理解能力
这使得我们极有希望真正实现
让机器理解自然语言这一目标
不过需要说明的是
人类的理解和语言模型的理解并不相同
语言模型的理解是指
能够明确接收到了哪些语言符号
并能处理不同语言符号之间的关系
但却不能将语言符号和指代对象进行关联
没有与现实对应
人类的理解则比语言模型的理解多了一个环节
能够将语言符号和指代对象关联起来
与现实对应起来
例如苹果这两个字是一个语言符号
当人类看到苹果这两个字时
会联想到一种看得见摸得着的水果
也就是苹果这个语言符号的指代对象
相比之下
语言模型可以明确
苹果这两个字也可以处理苹果
apple red和红的之间的关系
但却不认识这些符号的指代对象
就和会学话的鹦鹉一样
不知道自己说的词语指代什么
不过语言模型不理解符号的指代
其实不影响我们使用的
毕竟我们是把它当成工具
又不是把它当作一个独立改造世界的个体
因此只需要得到语言模型的回答
再由人类解读和实践即可
合理地使用大语言模型
就可以让一个普通人快捷准确地接触
各行各业的平均知识
我们可以将语言模型看作是一本能直接回答的
魔法百科全书
需要由人类来实践才有作用
也可以将语言模型类比为天龙八部中的王语嫣
精通武学却不会有功
需要与会武功的人配合才能发挥其才能
由于大圆模型所能改善的是群体协作过程中
创造继承应用知识时的语言处理效率
所以随着技术的发展
大语言模型对社会的影响范围
将和当初电脑的影响范围一样
及全社会
我们随便就能列出很多
跟大语言模型相结合的场景
跟搜索引擎结合
帮助用户精准寻找和筛选信息
比如微软的newbee
跟笔记工具结合辅助阅读和写作
比如notion flow us
我来跟办公软件结合
辅助文字处理
数据分析和演示制作
比如office的下一步动作
跟教育培训结合
制定个人的学习计划和学习材料
全天家教跟开发工具结合
辅助编写业务代码
调试纠错
跟客服系统结合
7x24小时随便问
没有任何情绪跟视频会议结合
多语翻译会议记录与总结
谈话查找的跟评论审核结合
筛选评论统计
舆论给出提醒
跟行业顾问结合
提供法律
医疗健身等指导
跟社交媒体结合
帮助寻找兴趣相投的用户和话题
跟视频娱乐结合
个性化推荐音乐电影小说
动漫跟游戏剧情结合
让npc给玩家带来更灵活的对话体验
稍微留一下就会发现
ChatGPT的报道主要分布于新闻界
学术界
教育界
商业界和内容生产行业
商业界有动作很好理解
毕竟商人对市场的感知敏锐
前三个领域动作频繁
正是因为他们与语言中的知识密切相关
学术界专注于创造知识
教育界专注于传承知识
而新闻界专注于传播信息
因此受到的影响最大
这也是为什么被称为美版头条的数字媒体公司
bus speed宣布将ChatGPT作为内容创作的一部分后
其股价暴涨三倍
尽管该公司之前曾以经济恶化为由
裁减了12%的员工
大语言模型对教育界的影响更加强烈
主要不是因为学生可以用它来写作业
而是因为他对我们现有的人才培养模式
提出了新的挑战
真正令人担心的是
按照现有模式培养出的学生
在未来五至10年后还能不能找到好工作
能否适应未来的就业市场
现代教育仍是一种
以传授既有知识为主的培养模式
起源可追溯到18世纪的普鲁士教育
虽然普鲁士教育的目的是为了批量培养
易于管理和服从权威的国民
但这套模式的其他方面
极好地契合了前两次工业革命中
市场对人才的需求
因为在当时的社会背景下
工人并不需要创造新知识
只需要继承一些既有知识
就能在后半生靠这些知识来维持生计
但在飞速发展的今天
市场变化越来越快
工具更新换代频繁
这种传授既有知识的培养模式
越来越难适应时代
因为无论传授什么既有知识
毕业前基本都会过时
所有人都需要不断学习新知识
因此自上个世纪60年代开始
终身学习的理念一直被反复推崇
人们也早就意识到
要将培养模式转换为
以培养学习能力和创造能力为主
这样无论学生毕业多久
工具变化多快
都可以通过高效的学习能力
快速掌握新技能
从实践中创造新知识
但是要实现这个目标并不容易
首先就需要一个更合适的理论框架来描述现象
因为我们在第三章已经看到
大语言模型也会创新
因此单纯喊出要培养创新性人才
没有实际指导意义
必须要对知识的层级做更精细的划分
将更高层次的创新和大语言模型的创新
加以区分
明确指出什么样的创新人才值得培养
又要如何培养
提供相应的培养工具和意义与实施的普及方案
并在各方角色的共同配合下
才有可能成功
因此一直推进缓慢
但ChatGPT的出现
迫使人们必须要加速这一推进了
因为一个非常现实的问题正摆在前面
5年后
如果学校传授的既有知识
任何人靠大语言模型就能实现
那该怎么办
这个问题可不是只靠禁止学生使用
ChatGPT就能解决的
因为未来的大语言模型只会更出色
更迅速更便宜
在这种情况下
相当于人人都配有一个
熟读人类既有知识的王语嫣
市场可不会因为学校的禁用而集体不用
另一方面
大语言模型对网络安全也带来了挑战
之前讲过
ChatGPT在开卷有益阶段
会对海量的互联网内容做单字接龙
然而互联网内容中不免存在一些带有偏见
歧视文化和意识形态侵袭的危害性言论
ChatGPT就有机会学到这些危害性言论的模
式
输出不良回答
此外也会有人刻意提问
如何编造杀猪盘等问题
用于不法行为
尽管在模板规范阶段有约束
但ChatGPT毕竟不像人类那样
真正的学会了知识
只是学到了传载知识的语言搭配模式
因此仍有可能被诱导输出帮助犯罪的知识
进而使防范违法犯罪变得更加困难
在群体协作时
人们使用的语言难免会泄露工作内容
如何确保提问的内容不被泄露
将是各个机构都关心的问题
很可能未来每一个机构都会自己部署大约模型
来确保安全
但这样又无法发挥数据规模效应
因此如何在保证各机构数据安全的前提下
实现联邦学习又有了新的挑战
这些问题加起来
你就会发现我国只能研发自己的大语言模型
篇幅问题
这里就不继续展开了
总结一下
本章讲了
ChatGPT的革命意义
是向人们展示大语言模型的可行性
人类群体通过语言处理来实现知识的创造
继承和应用
机器处理语言有着速度快
记忆大
覆盖广
无疲劳的优点
大语言模型能减轻语言处理工作
改变人与人
人与机器的协作方式
人类的理解和机器的理解不同
语言模型不知道符号的指代
大语言模型对社会的未来影响相当于口语
文字电脑
互联网对社会的影响
对教育界许秀杰
新闻界内容产生行业的影响颇深
他将方便人类对既有知识的继承
推进教育去培养高层次人才
也将带来网络安全和社会安全的新挑战
还剩一个问题
如何应对
人类的一大优势就在于善于利用工具
会先了解工具的优点和缺点
然后避开其缺点
将其优点用在合适的地方
ChatGPT非常强大
但他仍是一个没有意识的工具
不会主动配合人
面对空洞的提问
就会给出空洞的回答
需要被正确的使用才能发挥最大的价值
但我们却能看到
很多人专门将ChatGPT用于其最不擅长的领域
突出其缺点
或用最顶尖的标准突出其不足
很明显目的就是要否定他
这种锤子无用
因为他没有手灵活的否定
看起来不可理喻
但实际上却是人类在感受到威胁时的本能反应
因为我们都害怕被取代
然而很多人却害怕错了对象
把矛头指向了ChatGPT
指向了一个工具
可工具无法取代人
只有会用工具的人取代不会工具的人
任何性工具都可能引起取代
因为如果自己不用
而别人使用就会失去工具带来的竞争力
最终人们都不得不用
这种囚徒困境与ChatGPT无关
即使让ChatGPT从市场消失
取代现象也会随着其他新工具的出现而出现
也不会因为人们的害怕和抵触而消退
关于这一点
我们有过惨痛的历史教训
所以真正需要害怕的是
我们无法成为会用工具的人
可并没有人阻止我们探索工具
能阻止我们的只有我们自己的心态和学习能力
因此应对的第一步就是要克服自己的抵触心理
既然时代的车轮无法阻挡
那么抵触新工具只会让我们更晚接触新工具
更晚获得工具带来的优势
应对的第二部就是做好终身学习的准备
因为ChatGPT之后还会有新工具
这点看似简单
但对于习惯了应试教育的人而言并不容易
应试教育是一种高度特化的教育
由于最终的考核指标是分数
因此不论教育系统的设计目标是什么
最终学生的行为都难免会被特化为
仅服务于分数
凡是不能提高分数的行为都不被视为学习
即使是可以提高创造力的行为
这样长期规训的结果是
很多学生对学习一词的理解变得片面和扭曲
每当提到学习这个词时
这些学生就会联想到那种反人性的规训
好不容易熬到毕业了
现在被告知还要再学习
他们情绪上当然会抵触
好在这种抵触
很多人在工作一段时间后就能克服
因为他们慢慢会意识到
市场和工具的变化究竟有多快
在心态上也开始积极拥抱学习
然而不幸的是
即使心态上不再抵触学习
也还不得不克服过去形成的错误习惯
重塑自己的终身学习能力
这一步是最困难
不仅要去掌握抽象层次更高的认识论符号
学数学建模
批判性思维等内容
还要克服长期养成的习惯
但十多年的应试规训对一个人的影响太深远
很难在一朝一夕改变
每当这些人想学习时
就会条件反射式的重拾应试的学习习惯
自己把自己变回教室里
等着灌输的学生
会习惯性地等待别人的教授
习惯性的记忆别人的总结
很少思考知识到底是怎么来的
比如不少刚到大学的高中生
会觉得实验是在浪费时间
不如赶紧列出知识点
让他们去记
他们已经懒得思考事物之间的关联了
只想快点看到老师的总结
很多人意识到要学习使用ChatGPT时
脑中闪过的第一件事也是找本书或买个课
觉得没有这两样东西自己就学不了了
去年我们组织了建构社群
想要帮助人们重塑终身学习的能力
可在社群里也会发现
即使成员在认知上已经明白
不能脱离实体的去记忆符号
仍会在习惯上一次又一次地犯错
不得不反复提醒
能感觉到习惯了应试教育的学生
就仿佛是被动物园饲养的狮子
从小到大吃的都是送到嘴边的食物
以至于不认识野外的食物
忘记了如何自己获取食物
独立生存的能力逐渐退化
难以回到野外了
但即使再困难
也必须要克服
必须要完成对终身学习能力的重塑
因为过去那种学个知识
经历了多次科技革命的
我们也正处在一个加速时期
新工具的出现速度会越来越快
取代现象也会越来越频繁
只有学习能力才是应对未来的根本
或许我们的后代可以生下来
就处在全面培养学习能力和创造能力的系统中
从小就训练
适应快速变化的学习能力和创造能力
但对于处于转型期的我们而言
只有靠我们自己训练自己的终身学习能力
来应对随后加速变化的市场和工具
最后ChatGPT所掀起的浪潮
已经不仅仅涉及个人
还关乎到各国未来在国际中的地位
这项技术的进步将带来新的认知革命
重新定义人类知识
加速我们现实结构的改变
并重政治和社会
2月20日
法国负责数字转型的代表发生
ChatGPT确实存在歧视和操纵等风险
但法国不能错过这一波人工智能的新浪潮
应通过明确规范和加强管控来降低风险
3月五日
我国科技部部长也表示
要注重科技伦理趋利避害
并提到科技部在这方面的重视和布局
近期我国的各领域学者
也都针对ChatGPT举办了非常多的研讨会
现在大家应该能明白
ChatGPT到底是不是炒作了
再次强调大语言模型所影响的是知识的创造
继承和应用这三个环节所构成的学习系统
是任何生命系统得以延续的根本
决定着一个个体或文明
认识世界和改造世界的能力
在整个人类史以及整个生命史中
凡是学习系统的升级
都会伴随生命的跃升
不论是从单细胞生命到多细胞动物
还是从智人的崛起到多次科技革命
看过学习观演化史部分的观众
应该能理解这一点
在去年5月发布的视频中
我提到
人类正处在下一次跃升的进程中
但还缺少一项能升级学习系统的技术
而大语言模型很有可能就是这项技术
因为它正在改变人类群体应用知识的方式
和继承知识的方式
甚至可能在未来形成人机合作的科研
改变人类创造知识的方式
若真能如此
那么人类必将会因此步入下一个文明形态
中国错失了三次工业革命
这些年我们一直在实现民族的复兴
不能再错过这一次
未来的大圆模型
能够让每个人更快地获取承载知识的符号
会降低继承型人才的竞争力
不过每个人的学习能力和理解能力
将成为驾驭这项技术的瓶颈
如果个体的学习能力没有相应的提升
就无法充分发挥这项技术的优势
所以如果我们全都加强
对学习能力和高层次认知能力的训练
就能让我国在未来的国际竞争中获得优势
总的来说
ChatGPT的出现
确实带来了各种各样的问题和风险
存在准确性和可解释性的缺陷
存在科技伦理安全和结构性失业的冲击
存在民族文化和意识形态的侵袭
但这些问题和风险
所有国家都要面对
一样会有害怕和抵触的情绪
我们应该利用这一点
率先克服抵触心理
反过来抓住ChatGPT的机会
率先研究大语言模型的改进和配套技术的重组
率先培养终身学习能力和推动教育改革
率先做好科技伦理的约束和换岗转行的防备
主动输出我们的文化和价值观
至此视频的全部内容就结束了
感谢大家的观看
由于是面向大众的科普视频中使用了很多类比
也简化了不少细节
所以我们在视频的字幕上
都添加了原论文和相关资料的超链接
有需要的人可以直接点击字幕区或文
章区的蓝字部分进行跳转
至于如何根据ChatGPT的原理正确提问
如何利用ChatGPT来学习其他知识
会放到另一个视频中讲解


</body>
</html>
